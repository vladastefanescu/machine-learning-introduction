{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Introduction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlI5jmW3XnTr"
      },
      "source": [
        "# Import the necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncBYKmhFaZJs"
      },
      "source": [
        "# Load various printing functions\n",
        "\n",
        "# Pretty prints a data frame without display limits\n",
        "def print_df(df):\n",
        "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
        "        print(df)\n",
        "\n",
        "\n",
        "# Pretty prints the results of the classifier performance evaluation\n",
        "def print_classifier_results(accuracy, precision, recall, f1, mode):\n",
        "    print()\n",
        "    print('~~~~~~~~~~~~~~~~ CLASSIFICATION RESULTS (' + mode.upper() + ') ~~~~~~~~~~~~~~~~')\n",
        "    print(' Accuracy: ' + str(accuracy))\n",
        "    print('Precision: ' + str(precision))\n",
        "    print('   Recall: ' + str(recall))\n",
        "    print(' F1 Score: ' + str(f1))\n",
        "\n",
        "\n",
        "# Pretty prints the results of the regressor performance evaluation\n",
        "def print_regressor_results(rmse, mae, r_squared, mode):\n",
        "    print()\n",
        "    print('~~~~~~~~~~~~~~~~ REGRESSION RESULTS (' + mode.upper() + ') ~~~~~~~~~~~~~~~~')\n",
        "    print('Root Mean Squared Error (RMSE): ' + str(rmse))\n",
        "    print('     Mean Absolute Error (MAE): ' + str(mae))\n",
        "    print('               R-squared Score: ' + str(r_squared))\n",
        "\n",
        "\n",
        "# Pretty prints the results of the multiple classifications\n",
        "def print_fitting_results(accuracy_list):\n",
        "\n",
        "    print()\n",
        "    print('~~~~~~~~~~~~~~~~ CLASSIFICATION RESULTS ~~~~~~~~~~~~~~~~')\n",
        "\n",
        "    for accuracy_pair in accuracy_list:\n",
        "        print('Training Set Accuracy 1: ' + str(accuracy_pair[0]))\n",
        "        print('    Test Set Accuracy 1: ' + str(accuracy_pair[1]))\n",
        "        print()\n",
        "\n",
        "\n",
        "# Pretty prints the results of the clustering algorithm\n",
        "def print_clustering_results(silhouette_score):\n",
        "\n",
        "    print()\n",
        "    print('~~~~~~~~~~~~~~~~ CLUSTERING RESULTS ~~~~~~~~~~~~~~~~')\n",
        "    print('Silhouette Score: ' + str(silhouette_score))\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtnzaEOtgxHl"
      },
      "source": [
        "**Exercise 1: Classification**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK-CVa-Lg1y6",
        "outputId": "5af1dd23-434e-4387-e3f9-4df1ec397fde"
      },
      "source": [
        "# Load the dataset from the local session folder\n",
        "classification_dataset = pd.read_csv(\"diabetes.csv\")\n",
        "\n",
        "# Take a look at the first entries of the dataset\n",
        "print_df(classification_dataset.head())"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35        0  33.6   \n",
            "1            1       85             66             29        0  26.6   \n",
            "2            8      183             64              0        0  23.3   \n",
            "3            1       89             66             23       94  28.1   \n",
            "4            0      137             40             35      168  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YikM5ILSiRK5"
      },
      "source": [
        "# Extract the features from the dataset\n",
        "classification_X = dataset.iloc[:, :-1]\n",
        "# print_df(classification_X.head())\n",
        "\n",
        "# Extract the labels from the dataset\n",
        "classification_y = dataset.iloc[:, -1:]\n",
        "# print_df(classification_y.head())"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e-Ev9JRid7F"
      },
      "source": [
        "# Split the data into a training set and a test set with a 80-20 ratio\n",
        "classification_X_train, classification_X_test, classification_y_train, classification_y_test = train_test_split(classification_X, classification_y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTyLuOBGiqxj"
      },
      "source": [
        "# Build a classifier (less important: a decision tree will be used)\n",
        "classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Fit data from the training set to the classifier\n",
        "classifier.fit(classification_X_train, classification_y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "classification_y_pred = classifier.predict(classification_X_test)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0R2wgNpi4Aq"
      },
      "source": [
        "Task 2.A.\n",
        "\n",
        "Evaluate the performance of a classifier by manually computing accuracy, precision, recall and F1 score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBVsEPkwi8LL"
      },
      "source": [
        "# Computes the accuracy of the model using the confusion matrix\n",
        "def compute_accuracy(cm):\n",
        "    # TODO - TASK A\n",
        "    accuracy = None\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgXU3QoHjBku"
      },
      "source": [
        "# Computes the precision of the model using the confusion matrix\n",
        "def compute_precision(cm):\n",
        "    # TODO - TASK A\n",
        "    precision = None\n",
        "\n",
        "    return precision"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2fTgY3VjDGl"
      },
      "source": [
        "# Computes the recall of the model using the confusion matrix\n",
        "def compute_recall(cm):\n",
        "    # TODO - TASK A\n",
        "    recall = None\n",
        "\n",
        "    return recall"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQfdlB9TjFfw"
      },
      "source": [
        "# Computes the F1 score of the model using the precision and recall\n",
        "def compute_f1_score(precision, recall):\n",
        "    # TODO - TASK A\n",
        "    f1 = None\n",
        "\n",
        "    return f1"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDyqs3O2jLku",
        "outputId": "3168f36a-359a-4a1f-ee6d-76d060da6c53"
      },
      "source": [
        "# TODO - TASK A\n",
        "cm = None\n",
        "\n",
        "task_a_accuracy = compute_accuracy(cm)\n",
        "task_a_precision = compute_precision(cm)\n",
        "task_a_recall = compute_recall(cm)\n",
        "task_a_f1 = compute_f1_score(precision, recall)\n",
        "\n",
        "print_classifier_results(task_a_accuracy, task_a_precision, task_a_recall, task_a_f1, 'dumb')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "~~~~~~~~~~~~~~~~ CLASSIFICATION RESULTS (DUMB) ~~~~~~~~~~~~~~~~\n",
            " Accuracy: None\n",
            "Precision: None\n",
            "   Recall: None\n",
            " F1 Score: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEXMPg8UjdOI"
      },
      "source": [
        "Task 2.B.\n",
        "\n",
        "Evaluate the performance of a classifier using code written by others."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxfOFZFWjfEl",
        "outputId": "4a8a87b7-2b50-47c4-d35f-8574617ed664"
      },
      "source": [
        "# TODO - TASK B\n",
        "task_b_accuracy = None\n",
        "task_b_precision, task_b_recall, task_b_f1, _ = None, None, None, None\n",
        "\n",
        "print_classifier_results(task_b_accuracy, task_b_precision, task_b_recall, task_b_f1, 'smart')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "~~~~~~~~~~~~~~~~ CLASSIFICATION RESULTS (SMART) ~~~~~~~~~~~~~~~~\n",
            " Accuracy: None\n",
            "Precision: None\n",
            "   Recall: None\n",
            " F1 Score: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du9LS4X1b_H-"
      },
      "source": [
        "**Exercise 2: Linear Regression**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GDNE91bZXlO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6777443a-2dd9-4042-9797-2d085f7fb94b"
      },
      "source": [
        "# Load the dataset from the local session folder\n",
        "regression_dataset = pd.read_csv('diabetes.csv', dtype=np.float64)\n",
        "\n",
        "# Take a look at the first entries of the dataset\n",
        "print_df(regression_dataset.head())"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0          6.0    148.0           72.0           35.0      0.0  33.6   \n",
            "1          1.0     85.0           66.0           29.0      0.0  26.6   \n",
            "2          8.0    183.0           64.0            0.0      0.0  23.3   \n",
            "3          1.0     89.0           66.0           23.0     94.0  28.1   \n",
            "4          0.0    137.0           40.0           35.0    168.0  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction   Age  Outcome  \n",
            "0                     0.627  50.0      1.0  \n",
            "1                     0.351  31.0      0.0  \n",
            "2                     0.672  32.0      1.0  \n",
            "3                     0.167  21.0      0.0  \n",
            "4                     2.288  33.0      1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDCUAdnEawwg"
      },
      "source": [
        "# Extract the features from the dataset\n",
        "regression_X = regression_dataset.iloc[:, :-1]\n",
        "# print_df(regression_X.head())\n",
        "\n",
        "# Extract the labels from the dataset\n",
        "regression_y = regression_dataset.iloc[:, -1:]\n",
        "# print_df(regression_y.head())"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBhA_77fbDqT"
      },
      "source": [
        "# Split the data into a training set and a test set with a 80-20 ratio\n",
        "regression_X_train, regression_X_test, regression_y_train, regression_y_test = train_test_split(regression_X, regression_y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhKiXZGbbd-_"
      },
      "source": [
        "# Build a linear regressor\n",
        "regressor = LinearRegression()\n",
        "\n",
        "# Fit data from the training set to the regressor\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "regression_y_pred = regressor.predict(X_test)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lRDsGheeB_K"
      },
      "source": [
        "Task 1.A.\n",
        "\n",
        "Evaluate the performance of a regressor by manually computing RMSE, MAE and R2 score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS__DyPheD0k"
      },
      "source": [
        "# Computes the RMSE of the model\n",
        "def compute_rmse(y_test, y_pred):\n",
        "    # TODO - TASK A\n",
        "    return None"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlXKzdNheK9D"
      },
      "source": [
        "# Computes the MAE of the model\n",
        "def compute_mae(y_test, y_pred):\n",
        "    # TODO - TASK A\n",
        "    return None"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgBe8auWeRBh"
      },
      "source": [
        "# Computes the R-squared score of the model\n",
        "def compute_r2_score(y_test, y_pred):\n",
        "    # TODO - TASK A\n",
        "    return None"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYe8vromehIT",
        "outputId": "f23af290-9b39-4242-f23a-480d0ed12309"
      },
      "source": [
        "task_a_rmse = compute_rmse(y_test, y_pred)\n",
        "task_a_mae = compute_mae(y_test, y_pred)\n",
        "task_a_r_squared = compute_r2_score(y_test, y_pred)\n",
        "\n",
        "print_regressor_results(task_a_rmse, task_a_mae, task_a_r_squared, 'dumb')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "~~~~~~~~~~~~~~~~ REGRESSION RESULTS (DUMB) ~~~~~~~~~~~~~~~~\n",
            "Root Mean Squared Error (RMSE): None\n",
            "     Mean Absolute Error (MAE): None\n",
            "               R-squared Score: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoTUTYY_e5DY"
      },
      "source": [
        "Task 1.B.\n",
        "\n",
        "Evaluate the performance of a regressor using code written by others"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxpwzu6De65V"
      },
      "source": [
        "# TODO - TASK B\n",
        "task_b_rmse = None\n",
        "task_b_mae = None\n",
        "task_b_r_squared = None"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCGg44NNfc8b",
        "outputId": "4ca09e82-5f49-42d3-f5ca-1758e28b40a5"
      },
      "source": [
        "print_regressor_results(task_b_rmse, task_b_mae, task_b_r_squared, 'smart')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "~~~~~~~~~~~~~~~~ REGRESSION RESULTS (SMART) ~~~~~~~~~~~~~~~~\n",
            "Root Mean Squared Error (RMSE): None\n",
            "     Mean Absolute Error (MAE): None\n",
            "               R-squared Score: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8U4WIS-fngT"
      },
      "source": [
        "Task 1.C.\n",
        "\n",
        "Tweak some parameters and draw some plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I4toYvffzP8"
      },
      "source": [
        "# Plots the evolution of the RMSE when the dataset size varies\n",
        "def plot_rmse_evolution(X, y, chunks, min_chunk_size, max_chunk_size):\n",
        "    # TODO - TASK C\n",
        "    pass"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdph29_9gLzQ"
      },
      "source": [
        "# TODO - TASK C\n",
        "CHUNKS = 100\n",
        "MIN_CHUNK_SIZE = 1000\n",
        "MAX_CHUNK_SIZE = 1000000\n",
        "\n",
        "plot_rmse_evolution(regression_X, regression_y, CHUNKS, MIN_CHUNK_SIZE, MAX_CHUNK_SIZE)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywIb1viTl0jl"
      },
      "source": [
        "**Exercise 3: Fitting Behaviour**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rg4xLH0l3h9",
        "outputId": "f7c40310-2032-4488-b62f-6bcfb1d2f0fe"
      },
      "source": [
        "# Load the dataset from the local session folder\n",
        "fitting_dataset = pd.read_csv(\"diabetes.csv\")\n",
        "\n",
        "# Take a look at the first entries of the dataset\n",
        "print_df(fitting_dataset.head())"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0          6.0    148.0           72.0           35.0      0.0  33.6   \n",
            "1          1.0     85.0           66.0           29.0      0.0  26.6   \n",
            "2          8.0    183.0           64.0            0.0      0.0  23.3   \n",
            "3          1.0     89.0           66.0           23.0     94.0  28.1   \n",
            "4          0.0    137.0           40.0           35.0    168.0  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction   Age  Outcome  \n",
            "0                     0.627  50.0      1.0  \n",
            "1                     0.351  31.0      0.0  \n",
            "2                     0.672  32.0      1.0  \n",
            "3                     0.167  21.0      0.0  \n",
            "4                     2.288  33.0      1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exi9ikYnmIV9"
      },
      "source": [
        "# Extract the features from the dataset\n",
        "fitting_X = dataset.iloc[:, :-1]\n",
        "# print_df(fitting_X.head())\n",
        "\n",
        "# Extract the labels from the dataset\n",
        "fitting_y = dataset.iloc[:, -1:]\n",
        "# print_df(fitting_y.head())"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9nlVoJjmYUP"
      },
      "source": [
        "# Split the data into a training set and a test set with a 80-20 ratio\n",
        "fitting_X_train, fitting_X_test, fitting_y_train, fitting_y_test = train_test_split(fitting_X, fitting_y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm_vksG6mnzd"
      },
      "source": [
        "# Build 3 different trained models\n",
        "classifiers = [DecisionTreeClassifier(max_depth=1, random_state=42).fit(X_train, y_train),\n",
        "               DecisionTreeClassifier(max_depth=5, random_state=42).fit(X_train, y_train),\n",
        "               DecisionTreeClassifier(max_depth=32, random_state=42).fit(X_train, y_train)]"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt2i2F5QnLK_"
      },
      "source": [
        "Task 3.A.\n",
        "\n",
        "Write the code for generating 3 different fitting behaviours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjS8fh1mnPYA"
      },
      "source": [
        "# Makes prediction on both the training set and test set\n",
        "# HINT 1: You can reuse some code above\n",
        "# HINT 2: The models are already trained\n",
        "def make_predictions(clf, X_train, X_test, y_train, y_test):\n",
        "    # TODO - TASK A\n",
        "    train_accuracy = None\n",
        "    test_accuracy = None\n",
        "\n",
        "    return train_accuracy, test_accuracy"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Dh0prrgm-Nq",
        "outputId": "87ff5d6c-cd78-489f-eed6-b557d0cca980"
      },
      "source": [
        "# Make predictions on the training and test sets and evaluate the performance of each model\n",
        "accuracy_list = []\n",
        "for clf in classifiers:\n",
        "    accuracy_list.append(make_predictions(clf, fitting_X_train, fitting_X_test, fitting_y_train, fitting_y_test))\n",
        "\n",
        "# Print the performance evaluation results\n",
        "print_fitting_results(accuracy_list)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "~~~~~~~~~~~~~~~~ CLASSIFICATION RESULTS ~~~~~~~~~~~~~~~~\n",
            "Training Set Accuracy 1: None\n",
            "    Test Set Accuracy 1: None\n",
            "\n",
            "Training Set Accuracy 1: None\n",
            "    Test Set Accuracy 1: None\n",
            "\n",
            "Training Set Accuracy 1: None\n",
            "    Test Set Accuracy 1: None\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMVq5V7rne_o"
      },
      "source": [
        "Task 3.B.\n",
        "\n",
        "Write your conclusions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WTiKPCSOniVj",
        "outputId": "4be618a7-5821-4aaa-f8bf-45bb2c0722b9"
      },
      "source": [
        "\"\"\"\n",
        "TODO - TASK B\n",
        "\n",
        "Your conclusion here...\n",
        "\"\"\""
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nTODO - TASK B\\n\\nYour conclusion here...\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGpHojJxn5IT"
      },
      "source": [
        "**Exercise 4: Clustering**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlpxT-zyn7i_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}